## Day 6 / 30

## Day 6: October 31, 2019

### Neural networks with PyTorch

PyTorch has a module [nn]() that provides a way to efficiently build large neural networks.

MNIST dataset is a dataset which consists 28x28 pixels of greyscale handwritten digits.

![MNIST](mnist.png)


[Torchvision]()


A [Softmax](https://en.wikipedia.org/wiki/Softmax_function) function performs the softmax calculation and returns probability distributions for each example in the batch.


### Activation functions

- [Sigmoid Activation Function]()
- [Tanh (hyperbolic tangent) Activation Function]()
- [ReLU (rectified linear unit) Activation Function]()

![ACTIVATION](activation.png)

#### The ReLU function is used almost exclusively as the activation function for hidden layers.